version: '3.8'

services:
  writebot:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: writebot-app
    restart: unless-stopped
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=production
      - SECRET_KEY=${SECRET_KEY}
      - DATABASE_URL=${DATABASE_URL:-sqlite:///instance/writebot.db}
      - CACHE_TYPE=${CACHE_TYPE:-redis}
      - CACHE_REDIS_URL=redis://redis:6379/1
      - RATELIMIT_STORAGE_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - REDIS_URL=redis://redis:6379/0
      # Job queue settings
      - JOB_FILES_DIR=/app/webapp/job_storage
      - JOB_RETENTION_DAYS=${JOB_RETENTION_DAYS:-30}
    volumes:
      # Persist database and uploads
      - ./webapp/instance:/app/webapp/instance
      - ./webapp/logs:/app/webapp/logs
      - ./model/data:/app/model/data
      # Job storage for batch processing
      - job-storage:/app/webapp/job_storage
    depends_on:
      - redis
    networks:
      - writebot-network
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:5000/api/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Celery worker for background job processing
  celery-worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: writebot-celery-worker
    restart: unless-stopped
    command: celery -A webapp.celery_app:celery_app worker --loglevel=info --concurrency=1 -P solo
    environment:
      - FLASK_ENV=production
      - SECRET_KEY=${SECRET_KEY}
      - DATABASE_URL=${DATABASE_URL:-sqlite:///instance/writebot.db}
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - JOB_FILES_DIR=/app/webapp/job_storage
    volumes:
      - ./webapp/instance:/app/webapp/instance
      - ./webapp/logs:/app/webapp/logs
      - ./model/data:/app/model/data
      - job-storage:/app/webapp/job_storage
    depends_on:
      - redis
      - writebot
    networks:
      - writebot-network

  # Celery beat for scheduled tasks
  celery-beat:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: writebot-celery-beat
    restart: unless-stopped
    command: celery -A webapp.celery_app:celery_app beat --loglevel=info
    environment:
      - FLASK_ENV=production
      - SECRET_KEY=${SECRET_KEY}
      - DATABASE_URL=${DATABASE_URL:-sqlite:///instance/writebot.db}
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    volumes:
      - ./webapp/instance:/app/webapp/instance
    depends_on:
      - redis
      - celery-worker
    networks:
      - writebot-network

  redis:
    image: redis:7-alpine
    container_name: writebot-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - writebot-network
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  nginx:
    image: nginx:alpine
    container_name: writebot-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./deploy/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./deploy/ssl:/etc/nginx/ssl:ro
      - ./webapp/static:/usr/share/nginx/html/static:ro
    depends_on:
      - writebot
    networks:
      - writebot-network
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  redis-data:
    driver: local
  job-storage:
    driver: local

networks:
  writebot-network:
    driver: bridge
